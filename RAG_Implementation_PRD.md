
üöÄ Product Requirements Document (PRD)

RAG Functionality for Agent Application using OpenAI Retrieval Services

Author: Ashish
Audience: Codex Engineering
Version: v1.0
Goal: Implement enterprise-grade Retrieval Augmented Generation for Agents (Voice + Chat) using OpenAI‚Äôs native RAG (Retrieval / File Search / Responses API).

‚∏ª

1. Overview

The current Agent Application supports:
	‚Ä¢	Voice agents (OpenAI Realtime)
	‚Ä¢	Chat agents (agentic chat widget)
	‚Ä¢	MCP tools
	‚Ä¢	n8n workflows
	‚Ä¢	Agent presets & instructions
	‚Ä¢	Multi-tenant Supabase architecture

Missing capability:

üîç Agents cannot yet use organizational knowledge (PDFs, documents, manuals, SOPs) to answer questions.

We want to add first-class RAG, powered by OpenAI‚Äôs Retrieval / File Search APIs, without building our own embedding/vector infrastructure.

‚∏ª

2. Objectives

Primary Objectives
	1.	Allow tenants to create/manage Knowledge Spaces (KBs).
	2.	Let agents attach one or more KBs to their configuration.
	3.	Enable automatic RAG-enhanced responses for:
	‚Ä¢	Voice agents (OpenAI Realtime pipeline)
	‚Ä¢	Chat agents (UI + web widget)
	4.	Use OpenAI Retrieval/File Search/Responses API (no custom embeddings).
	5.	Full logging and observability inside Supabase.

Secondary Objectives
	‚Ä¢	Multi-tenant isolation (RLS)
	‚Ä¢	Support uploads (PDF, DOCX, TXT, MD, HTML)
	‚Ä¢	Dashboard UI for managing KBs & documents

Non-Goals (v1)
	‚Ä¢	No custom vector DB (Supabase vector extension optional)
	‚Ä¢	No fine-tuning
	‚Ä¢	No large-scale crawling (Confluence, SharePoint)‚Äîfuture enhancements

‚∏ª

3. Product Scope

3.1 Users

User Type	Needs
Tenant admin	Upload docs, create KB spaces
Developer	Attach KBs to agents
End user	Receive accurate, knowledge-aware responses
Voice agent caller	Get info grounded in org documents
Internal operator	View retrieval logs


‚∏ª

4. Key Concepts

Knowledge Space (KB Space)

Logical grouping of documents. E.g., ‚ÄúHealthcare Claims KB‚Äù, ‚ÄúUtilities Billing KB‚Äù.

Documents

PDFs, URLs, manual text. Each generates OpenAI hosted content.

RAG Query

Any agent turn that uses OpenAI file-search to fetch context documents.

Agent Knowledge Binding

Agent config stores a list of KB Spaces ‚Üí RAG automatically activates.

‚∏ª

5. User Stories
	1.	As a tenant admin, I can create a KB space.
	2.	As a tenant admin, I can upload docs to a KB.
	3.	As a developer, I can attach KBs to an agent.
	4.	As an end user, the agent answers questions using uploaded docs.
	5.	As a voice caller, the realtime agent uses my KB to answer.
	6.	As an operator, I can see RAG logs and what documents were used.

‚∏ª

6. System Architecture

Frontend ‚Üí Next.js API Routes ‚Üí Supabase ‚Üí OpenAI Retrieval ‚Üí Agents (Chat + Voice)

Where RAG happens
	‚Ä¢	Chat agent ‚Üí /api/agent/chat (extended)
	‚Ä¢	Voice agent ‚Üí Server-side text pipeline ‚Üí Retrieval ‚Üí Realtime model
	‚Ä¢	All retrieval uses OpenAI‚Äôs file_search / retrieval features.

‚∏ª

7. Functional Requirements

7.1 Knowledge Space Management

FR-1 Create KB Space
	‚Ä¢	Inputs: name, desc, tenant_id
	‚Ä¢	Creates:
	‚Ä¢	Row in va_rag_spaces
	‚Ä¢	OpenAI vector-store equivalent (via openai.rag / file_search API)
	‚Ä¢	Returns vector_store_id / datatstore_id

FR-2 Edit/Delete KB Space
	‚Ä¢	Soft delete required
	‚Ä¢	RLS enforces tenant isolation

FR-3 View KB Spaces
	‚Ä¢	List KBs with document counts and statuses

‚∏ª

7.2 Document Ingestion

FR-4 Upload Document

Supported types: PDF, DOCX, TXT, MD, HTML.

Flow:
	1.	Upload ‚Üí Next.js route
	2.	Store metadata in Supabase (va_rag_documents)
	3.	Upload file to OpenAI files endpoint
	4.	Associate file with RAG datastore (vector store)
	5.	Mark status indexing ‚Üí ready

FR-5 Manual Text Paste
	‚Ä¢	Admin pastes text; system creates .txt or direct insertion via RAG API.

FR-6 URL Snapshot (optional v1.1)

‚∏ª

7.3 Agents With RAG

FR-7 Agents Can Attach KB Spaces

In agent config:

knowledge_spaces: [uuid1, uuid2]

FR-8 Chat Agent RAG Flow

On each user message:
	1.	Get agent config
	2.	Get KB spaces ‚Üí get vector_store_ids
	3.	Call OpenAI Retrieval via Responses API:

POST /v1/responses

{
  "model": "gpt-4.1-mini",
  "input": user_message,
  "file_search": {
    "vector_store_ids": [...]
  }
}

	4.	Receive answer + citations
	5.	Log retrieved docs
	6.	Return to UI

FR-9 Voice Agent RAG Flow

Pipeline:

Speech ‚Üí Text ‚Üí RAG search ‚Üí LLM ‚Üí Speech

For each query chunk:

openai.responses.create({
  model: "gpt-4.1-mini",
  input: transcript_segment,
  file_search: { vector_store_ids: [...] }
})


‚∏ª

7.4 Logging

FR-10 RAG Logs per Turn

Store in va_rag_logs:
	‚Ä¢	agent_config_id
	‚Ä¢	conversation_id
	‚Ä¢	user_query
	‚Ä¢	retrieved documents
	‚Ä¢	retrieved snippet text
	‚Ä¢	openai_vector_store_ids
	‚Ä¢	timestamps

‚∏ª

8. Supabase Schema Requirements (Final)

8.1 va_rag_spaces

create table public.va_rag_spaces (
  id uuid primary key default gen_random_uuid(),
  tenant_id uuid not null,
  name text not null,
  description text,
  vector_store_id text, -- OpenAI datastore / file_search store
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);


‚∏ª

8.2 va_rag_documents

create table public.va_rag_documents (
  id uuid primary key default gen_random_uuid(),
  space_id uuid not null references va_rag_spaces(id) on delete cascade,
  tenant_id uuid not null,
  title text,
  source_type text not null,  -- file, url, text
  openai_file_id text,
  status text default 'indexing',
  error_message text,
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);


‚∏ª

8.3 va_rag_agent_spaces

create table public.va_rag_agent_spaces (
  id uuid primary key default gen_random_uuid(),
  agent_config_id uuid not null references va_agent_configs(id),
  space_id uuid not null references va_rag_spaces(id),
  created_at timestamptz default now(),
  unique(agent_config_id, space_id)
);


‚∏ª

8.4 va_rag_logs

create table public.va_rag_logs (
  id uuid primary key default gen_random_uuid(),
  tenant_id uuid not null,
  agent_config_id uuid not null,
  conversation_id uuid,
  turn_id uuid,
  query_text text not null,
  vector_store_ids text[],
  retrieved jsonb,
  model text,
  latency_ms integer,
  token_usage jsonb,
  created_at timestamptz default now()
);


‚∏ª

9. API Routes Specification

9.1 POST /api/rag/spaces

Create KB Space + Create Vector Store.

9.2 POST /api/rag/docs/upload

Upload file ‚Üí OpenAI ‚Üí Metadata row.

9.3 POST /api/agent/chat

Extend existing route to:
	‚Ä¢	Detect KBs
	‚Ä¢	Perform retrieval
	‚Ä¢	Return grounded answer

9.4 POST /api/agent/voice

Add RAG inside server-side transcript handler.

9.5 GET /api/rag/logs

Paginated logs.

‚∏ª

10. Application Logic

10.1 Query Flow (Chat Agent)

User Query
‚Üí Agent Config
‚Üí KB Spaces ‚Üí vector_store_ids
‚Üí Retrieval via Responses API
‚Üí Answer + citations
‚Üí Save logs
‚Üí Return response


‚∏ª

11. UI Requirements (Agent Studio)

Admin KB Console
	‚Ä¢	Create KB
	‚Ä¢	Upload documents
	‚Ä¢	View status (indexing / ready)
	‚Ä¢	Delete / archive
	‚Ä¢	Document list

Agent Config UI
	‚Ä¢	Checkbox list of KB Spaces
	‚Ä¢	RAG mode:
	‚Ä¢	Assist only
	‚Ä¢	Guardrail (don‚Äôt hallucinate)

Chat Testing UI
	‚Ä¢	‚ÄúKnowledge used‚Äù preview panel
	‚Ä¢	Retrieved snippets with citation markers

‚∏ª

12. Security & RLS

Enforce RLS on:
	‚Ä¢	va_rag_spaces
	‚Ä¢	va_rag_documents
	‚Ä¢	va_rag_agent_spaces
	‚Ä¢	va_rag_logs

Policy:

tenant_id = auth.jwt().tenant_id


‚∏ª

13. Performance & Limits
	‚Ä¢	Target RAG latency: < 1.5s per LLM call
	‚Ä¢	Document size limit: 25MB per file
	‚Ä¢	Total KB per tenant: soft limit 2GB (OpenAI hosting)
	‚Ä¢	Cache vector_store_ids in memory for faster lookup

‚∏ª

14. Edge Cases
	‚Ä¢	If retrieval returns zero results:
	‚Ä¢	Assist mode ‚Üí LLM answers normally
	‚Ä¢	Guardrail mode ‚Üí fallback answer: ‚ÄúInsufficient info‚Äù
	‚Ä¢	If OpenAI is down:
	‚Ä¢	Fallback to non-RAG model

‚∏ª

15. Future Enhancements
	‚Ä¢	Indexed URL scraping (Sitemap ‚Üí OpenAI ingestion)
	‚Ä¢	Connecting multiple stores to an agent with weighted relevance
	‚Ä¢	Domain-specific chunking (tables, PDFs, OCR)

‚∏ª

16. Acceptance Criteria
	1.	Agents can answer questions using uploaded documents.
	2.	KB management UI works end-to-end.
	3.	Logs show retrieved document snippets.
	4.	Voice agent and chat agent both use RAG consistently.
	5.	Multi-tenancy isolation enforced.

‚∏ª

‚úîÔ∏è Final Notes for Codex
	‚Ä¢	Use OpenAI Responses API with file_search (recommended by OpenAI).
	‚Ä¢	Avoid home-grown embeddings unless needed for fallback.
	‚Ä¢	All RAG flows must be internal (server-side) for security.
	‚Ä¢	Always log what documents were retrieved.

